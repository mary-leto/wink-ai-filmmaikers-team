{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "QY03__B4AqJL",
        "outputId": "14aa3464-e7fe-4f53-b808-2963604bb48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] --input INPUT --output_dir OUTPUT_DIR\n",
            "                                [--min_text_len MIN_TEXT_LEN]\n",
            "                                [--max_examples MAX_EXAMPLES]\n",
            "colab_kernel_launcher.py: error: the following arguments are required: --input, --output_dir\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/argparse.py\", line 1943, in _parse_known_args2\n",
            "    namespace, args = self._parse_known_args(args, namespace, intermixed)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/argparse.py\", line 2230, in _parse_known_args\n",
            "    raise ArgumentError(None, _('the following arguments are required: %s') %\n",
            "argparse.ArgumentError: the following arguments are required: --input, --output_dir\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-3735302977.py\", line 239, in <cell line: 0>\n",
            "    main()\n",
            "  File \"/tmp/ipython-input-3735302977.py\", line 205, in main\n",
            "    args = parser.parse_args()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/argparse.py\", line 1904, in parse_args\n",
            "    args, argv = self.parse_known_args(args, namespace)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/argparse.py\", line 1914, in parse_known_args\n",
            "    return self._parse_known_args2(args, namespace, intermixed=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/argparse.py\", line 1945, in _parse_known_args2\n",
            "    self.error(str(err))\n",
            "  File \"/usr/lib/python3.12/argparse.py\", line 2650, in error\n",
            "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
            "  File \"/usr/lib/python3.12/argparse.py\", line 2637, in exit\n",
            "    _sys.exit(status)\n",
            "SystemExit: 2\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1701, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args2\u001b[0;34m(self, args, namespace, intermixed)\u001b[0m\n\u001b[1;32m   1942\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1943\u001b[0;31m                 \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermixed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1944\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace, intermixed)\u001b[0m\n\u001b[1;32m   2229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequired_actions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m             raise ArgumentError(None, _('the following arguments are required: %s') %\n\u001b[0m\u001b[1;32m   2231\u001b[0m                        ', '.join(required_actions))\n",
            "\u001b[0;31mArgumentError\u001b[0m: the following arguments are required: --input, --output_dir",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3735302977.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3735302977.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1904\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1913\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermixed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args2\u001b[0;34m(self, args, namespace, intermixed)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2650\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2636\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2637\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 2",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# НАСТРОЙКИ ПОД ВАШ ДАТАСЕТ\n",
        "# ---------------------------\n",
        "\n",
        "COLUMN_MAP = {\n",
        "    \"script_id\": \"script_id\",\n",
        "    \"scene_id\": \"scene_id\",\n",
        "    \"scene_text\": \"scene_text\",      # текст сцены / блок сценария\n",
        "    \"location\": \"location\",\n",
        "    \"time_of_day\": \"time_of_day\",\n",
        "    \"characters\": \"characters\",\n",
        "    \"extras\": \"extras\",\n",
        "    \"props\": \"props\",\n",
        "    \"fx\": \"fx\",                      # спецэффекты\n",
        "    # \"notes\": \"notes\",              # если есть — можно добавить\n",
        "}\n",
        "\n",
        "# Разделитель списков в ячейках (персонажи, реквизит и т.п.)\n",
        "LIST_SEPARATOR = \";\"\n",
        "\n",
        "\n",
        "def load_table(path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Загрузка CSV или Excel в pandas.\"\"\"\n",
        "    if path.suffix.lower() in [\".xlsx\", \".xls\"]:\n",
        "        df = pd.read_excel(path)\n",
        "    else:\n",
        "        df = pd.read_csv(path)\n",
        "    return df\n",
        "\n",
        "\n",
        "def normalize_list_cell(value):\n",
        "    \"\"\"\n",
        "    Преобразуем строку вроде \"МИША; АЛИНА;  \" в список [\"МИША\", \"АЛИНА\"].\n",
        "    Если NaN/пусто — возвращаем пустой список.\n",
        "    \"\"\"\n",
        "    if pd.isna(value):\n",
        "        return []\n",
        "    if isinstance(value, list):\n",
        "        # Уже список\n",
        "        return [str(x).strip() for x in value if str(x).strip()]\n",
        "    text = str(value)\n",
        "    parts = [p.strip() for p in text.split(LIST_SEPARATOR)]\n",
        "    return [p for p in parts if p]\n",
        "\n",
        "\n",
        "def normalize_time_of_day(value):\n",
        "    \"\"\"\n",
        "    Нормализация времени суток к фиксированному набору.\n",
        "    При необходимости расширьте/измените маппинг.\n",
        "    \"\"\"\n",
        "    if pd.isna(value):\n",
        "        return None\n",
        "    text = str(value).strip().lower()\n",
        "\n",
        "    mapping = {\n",
        "        \"день\": \"day\",\n",
        "        \"днём\": \"day\",\n",
        "        \"утро\": \"morning\",\n",
        "        \"ночь\": \"night\",\n",
        "        \"ночью\": \"night\",\n",
        "        \"вечер\": \"evening\",\n",
        "        \"вечером\": \"evening\",\n",
        "        \"day\": \"day\",\n",
        "        \"night\": \"night\",\n",
        "        \"morning\": \"morning\",\n",
        "        \"evening\": \"evening\",\n",
        "    }\n",
        "\n",
        "    # если совпадает напрямую\n",
        "    if text in mapping:\n",
        "        return mapping[text]\n",
        "\n",
        "    # простые эвристики\n",
        "    if \"ноч\" in text:\n",
        "        return \"night\"\n",
        "    if \"утр\" in text:\n",
        "        return \"morning\"\n",
        "    if \"вечер\" in text:\n",
        "        return \"evening\"\n",
        "    if \"день\" in text or \"day\" in text:\n",
        "        return \"day\"\n",
        "\n",
        "    return None  # если не смогли классифицировать\n",
        "\n",
        "\n",
        "def normalize_location(value):\n",
        "    \"\"\"Простейшая нормализация локации (обрезка пробелов, приведение пробелов).\"\"\"\n",
        "    if pd.isna(value):\n",
        "        return None\n",
        "    text = \" \".join(str(value).split())\n",
        "    return text if text else None\n",
        "\n",
        "\n",
        "def filter_good_scenes(df: pd.DataFrame, min_text_len: int = 50):\n",
        "    \"\"\"\n",
        "    Отбираем сцены, которые подойдут в золотой стандарт:\n",
        "    - есть текст\n",
        "    - есть локация и/или время суток\n",
        "    - длина текста не слишком маленькая\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # нормализуем базовые поля\n",
        "    df[\"scene_text\"] = df[COLUMN_MAP[\"scene_text\"]].astype(str).str.strip()\n",
        "\n",
        "    df[\"location_norm\"] = df[COLUMN_MAP[\"location\"]].map(normalize_location)\n",
        "    df[\"time_of_day_norm\"] = df[COLUMN_MAP[\"time_of_day\"]].map(normalize_time_of_day)\n",
        "\n",
        "    # минимальная длина текста\n",
        "    df = df[df[\"scene_text\"].str.len() >= min_text_len]\n",
        "\n",
        "    # хотя бы что-то одно: локация или время суток\n",
        "    df = df[(df[\"location_norm\"].notna()) | (df[\"time_of_day_norm\"].notna())]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def row_to_example(row) -> dict:\n",
        "    \"\"\"\n",
        "    Преобразование строки DataFrame в JSON-пример для обучения/оценки.\n",
        "    \"\"\"\n",
        "    example = {\n",
        "        \"script_id\": str(row[COLUMN_MAP[\"script_id\"]]),\n",
        "        \"scene_id\": str(row[COLUMN_MAP[\"scene_id\"]]),\n",
        "        \"text\": str(row[\"scene_text\"]),\n",
        "        \"labels\": {\n",
        "            \"location\": row[\"location_norm\"],\n",
        "            \"time_of_day\": row[\"time_of_day_norm\"],\n",
        "            \"characters\": normalize_list_cell(row.get(COLUMN_MAP[\"characters\"], None)),\n",
        "            \"extras\": normalize_list_cell(row.get(COLUMN_MAP[\"extras\"], None)),\n",
        "            \"props\": normalize_list_cell(row.get(COLUMN_MAP[\"props\"], None)),\n",
        "            \"fx\": normalize_list_cell(row.get(COLUMN_MAP[\"fx\"], None)),\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Можно добавить notes, если есть\n",
        "    # if \"notes\" in COLUMN_MAP:\n",
        "    #     example[\"labels\"][\"notes\"] = str(row.get(COLUMN_MAP[\"notes\"], \"\"))\n",
        "\n",
        "    return example\n",
        "\n",
        "\n",
        "def save_jsonl(examples, path: Path):\n",
        "    \"\"\"Сохраняем список dict в JSONL.\"\"\"\n",
        "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        for ex in examples:\n",
        "            f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "\n",
        "def split_train_dev_test(examples, train_ratio=0.8, dev_ratio=0.1, seed=42):\n",
        "    \"\"\"\n",
        "    Разбиваем примеры на train / dev / test.\n",
        "    По умолчанию: 80% / 10% / 10%.\n",
        "    \"\"\"\n",
        "    random.Random(seed).shuffle(examples)\n",
        "    n = len(examples)\n",
        "    n_train = int(n * train_ratio)\n",
        "    n_dev = int(n * dev_ratio)\n",
        "    n_test = n - n_train - n_dev\n",
        "\n",
        "    train = examples[:n_train]\n",
        "    dev = examples[n_train:n_train + n_dev]\n",
        "    test = examples[n_train + n_dev:]\n",
        "\n",
        "    return train, dev, test\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Выделение золотого стандарта из табличного датасета сценариев.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--input\",\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Путь к входному CSV/Excel с таблицей сцен.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\",\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Папка для сохранения JSONL (train/dev/test).\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--min_text_len\",\n",
        "        type=int,\n",
        "        default=50,\n",
        "        help=\"Минимальная длина текста сцены для попадания в золотой стандарт.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_examples\",\n",
        "        type=int,\n",
        "        default=0,\n",
        "        help=\"Максимальное количество примеров (0 = использовать все подходящие).\",\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    input_path = Path(args.input)\n",
        "    output_dir = Path(args.output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f\"Загружаем таблицу из: {input_path}\")\n",
        "    df = load_table(input_path)\n",
        "\n",
        "    print(\"Фильтруем сцены для золотого стандарта...\")\n",
        "    df_good = filter_good_scenes(df, min_text_len=args.min_text_len)\n",
        "    print(f\"Подходящих сцен: {len(df_good)}\")\n",
        "\n",
        "    examples = [row_to_example(row) for _, row in df_good.iterrows()]\n",
        "\n",
        "    if args.max_examples > 0 and len(examples) > args.max_examples:\n",
        "        print(f\"Ограничиваем число примеров до {args.max_examples}\")\n",
        "        examples = random.sample(examples, args.max_examples)\n",
        "\n",
        "    train, dev, test = split_train_dev_test(examples)\n",
        "\n",
        "    print(f\"train: {len(train)}, dev: {len(dev)}, test: {len(test)}\")\n",
        "\n",
        "    save_jsonl(train, output_dir / \"gold_train.jsonl\")\n",
        "    save_jsonl(dev, output_dir / \"gold_dev.jsonl\")\n",
        "    save_jsonl(test, output_dir / \"gold_test.jsonl\")\n",
        "\n",
        "    print(\"Готово. Файлы сохранены:\")\n",
        "    print(f\"- {output_dir / 'gold_train.jsonl'}\")\n",
        "    print(f\"- {output_dir / 'gold_dev.jsonl'}\")\n",
        "    print(f\"- {output_dir / 'gold_test.jsonl'}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "юпд после кода ревью"
      ],
      "metadata": {
        "id": "oMW21jRLBfTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import ast\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# НАСТРОЙКИ ПОД ВАШ ДАТАСЕТ\n",
        "# ---------------------------\n",
        "\n",
        "COLUMN_MAP = {\n",
        "    \"script_id\": \"script_id\",\n",
        "    \"scene_id\": \"scene_id\",\n",
        "    \"scene_text\": \"scene_text\",      # текст сцены / блок сценария\n",
        "    \"location\": \"location\",\n",
        "    \"time_of_day\": \"time_of_day\",\n",
        "    \"characters\": \"characters\",\n",
        "    \"extras\": \"extras\",\n",
        "    \"props\": \"props\",\n",
        "    \"fx\": \"fx\",                      # спецэффекты\n",
        "    # \"notes\": \"notes\",              # если есть — можно добавить\n",
        "}\n",
        "\n",
        "# Разделитель списков в ячейках (персонажи, реквизит и т.п.)\n",
        "LIST_SEPARATOR = \";\"\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ\n",
        "# ---------------------------\n",
        "\n",
        "def load_table(path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Загрузка CSV или Excel в pandas.\"\"\"\n",
        "    if path.suffix.lower() in [\".xlsx\", \".xls\"]:\n",
        "        df = pd.read_excel(path)\n",
        "    else:\n",
        "        df = pd.read_csv(path)\n",
        "    return df\n",
        "\n",
        "\n",
        "def validate_columns(df: pd.DataFrame):\n",
        "    \"\"\"Проверяем наличие обязательных колонок в датасете.\"\"\"\n",
        "    required_columns = [\n",
        "        COLUMN_MAP[\"script_id\"],\n",
        "        COLUMN_MAP[\"scene_id\"],\n",
        "        COLUMN_MAP[\"scene_text\"],\n",
        "        COLUMN_MAP[\"location\"],\n",
        "        COLUMN_MAP[\"time_of_day\"],\n",
        "    ]\n",
        "    missing = [c for c in required_columns if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Отсутствуют обязательные колонки в датасете: {missing}\")\n",
        "\n",
        "\n",
        "def safe_str(v):\n",
        "    \"\"\"Безопасное преобразование в строку (NaN → None).\"\"\"\n",
        "    if pd.isna(v):\n",
        "        return None\n",
        "    return str(v)\n",
        "\n",
        "\n",
        "def normalize_list_cell(value):\n",
        "    \"\"\"\n",
        "    Преобразуем содержимое ячейки в список строк.\n",
        "    Поддерживаем:\n",
        "    - NaN → []\n",
        "    - уже список → нормализуем элементы\n",
        "    - JSON-список в строке → парсим\n",
        "    - строку с разделителем LIST_SEPARATOR → сплитим\n",
        "    \"\"\"\n",
        "    if pd.isna(value):\n",
        "        return []\n",
        "    if isinstance(value, list):\n",
        "        return [str(x).strip() for x in value if str(x).strip()]\n",
        "\n",
        "    text = str(value).strip()\n",
        "    if not text:\n",
        "        return []\n",
        "\n",
        "    # Пытаемся распарсить JSON-подобный список: [\"МИША\", \"АЛИНА\"]\n",
        "    if text.startswith(\"[\") and text.endswith(\"]\"):\n",
        "        try:\n",
        "            arr = ast.literal_eval(text)\n",
        "            if isinstance(arr, list):\n",
        "                return [str(x).strip() for x in arr if str(x).strip()]\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    parts = [p.strip() for p in text.split(LIST_SEPARATOR)]\n",
        "    return [p for p in parts if p]\n",
        "\n",
        "\n",
        "def normalize_time_of_day(value):\n",
        "    \"\"\"\n",
        "    Нормализация времени суток к фиксированному набору.\n",
        "    При необходимости расширьте/измените маппинг.\n",
        "    \"\"\"\n",
        "    if pd.isna(value):\n",
        "        return None\n",
        "    text = str(value).strip().lower()\n",
        "\n",
        "    mapping = {\n",
        "        \"день\": \"day\",\n",
        "        \"днём\": \"day\",\n",
        "        \"днем\": \"day\",\n",
        "        \"утро\": \"morning\",\n",
        "        \"ночь\": \"night\",\n",
        "        \"ночью\": \"night\",\n",
        "        \"вечер\": \"evening\",\n",
        "        \"вечером\": \"evening\",\n",
        "        \"day\": \"day\",\n",
        "        \"night\": \"night\",\n",
        "        \"morning\": \"morning\",\n",
        "        \"evening\": \"evening\",\n",
        "    }\n",
        "\n",
        "    if text in mapping:\n",
        "        return mapping[text]\n",
        "\n",
        "    # простые эвристики, если значение не нормализовано\n",
        "    if \"ноч\" in text:\n",
        "        return \"night\"\n",
        "    if \"утр\" in text:\n",
        "        return \"morning\"\n",
        "    if \"вечер\" in text:\n",
        "        return \"evening\"\n",
        "    if \"день\" in text or \"day\" in text:\n",
        "        return \"day\"\n",
        "\n",
        "    return None  # если не смогли классифицировать\n",
        "\n",
        "\n",
        "def normalize_location(value):\n",
        "    \"\"\"Простейшая нормализация локации (трим + схлопывание пробелов).\"\"\"\n",
        "    if pd.isna(value):\n",
        "        return None\n",
        "    text = \" \".join(str(value).split())\n",
        "    return text if text else None\n",
        "\n",
        "\n",
        "def filter_good_scenes(df: pd.DataFrame, min_text_len: int = 50):\n",
        "    \"\"\"\n",
        "    Отбираем сцены, которые подойдут в золотой стандарт:\n",
        "    - есть текст\n",
        "    - есть локация и/или время суток\n",
        "    - длина текста не слишком маленькая\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    total = len(df)\n",
        "    print(f\"Всего строк в исходном датасете: {total}\")\n",
        "\n",
        "    # нормализуем базовые поля\n",
        "    df[\"scene_text\"] = df[COLUMN_MAP[\"scene_text\"]].astype(str).str.strip()\n",
        "    df[\"location_norm\"] = df[COLUMN_MAP[\"location\"]].map(normalize_location)\n",
        "    df[\"time_of_day_norm\"] = df[COLUMN_MAP[\"time_of_day\"]].map(normalize_time_of_day)\n",
        "\n",
        "    # минимальная длина текста\n",
        "    before_len = len(df)\n",
        "    df = df[df[\"scene_text\"].str.len() >= min_text_len]\n",
        "    after_len = len(df)\n",
        "    print(f\"Фильтр по длине текста (>= {min_text_len}): оставлено {after_len}/{before_len}\")\n",
        "\n",
        "    # хотя бы что-то одно: локация или время суток\n",
        "    before_loc = len(df)\n",
        "    df = df[(df[\"location_norm\"].notna()) | (df[\"time_of_day_norm\"].notna())]\n",
        "    after_loc = len(df)\n",
        "    print(f\"Фильтр по локации/времени суток: оставлено {after_loc}/{before_loc}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def row_to_example(row) -> dict:\n",
        "    \"\"\"\n",
        "    Преобразование строки DataFrame в JSON-пример для обучения/оценки.\n",
        "    \"\"\"\n",
        "    example = {\n",
        "        \"script_id\": safe_str(row[COLUMN_MAP[\"script_id\"]]),\n",
        "        \"scene_id\": safe_str(row[COLUMN_MAP[\"scene_id\"]]),\n",
        "        \"text\": str(row[\"scene_text\"]),\n",
        "        \"labels\": {\n",
        "            \"location\": row[\"location_norm\"],\n",
        "            \"time_of_day\": row[\"time_of_day_norm\"],\n",
        "            \"characters\": normalize_list_cell(row.get(COLUMN_MAP[\"characters\"], None)),\n",
        "            \"extras\": normalize_list_cell(row.get(COLUMN_MAP[\"extras\"], None)),\n",
        "            \"props\": normalize_list_cell(row.get(COLUMN_MAP[\"props\"], None)),\n",
        "            \"fx\": normalize_list_cell(row.get(COLUMN_MAP[\"fx\"], None)),\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Можно добавить notes, если есть\n",
        "    # if \"notes\" in COLUMN_MAP:\n",
        "    #     example[\"labels\"][\"notes\"] = safe_str(row.get(COLUMN_MAP[\"notes\"], \"\"))\n",
        "\n",
        "    return example\n",
        "\n",
        "\n",
        "def save_jsonl(examples, path: Path):\n",
        "    \"\"\"Сохраняем список dict в JSONL.\"\"\"\n",
        "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        for ex in examples:\n",
        "            f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "\n",
        "def split_train_dev_test_by_script(\n",
        "    examples,\n",
        "    train_ratio=0.8,\n",
        "    dev_ratio=0.1,\n",
        "    seed=42,\n",
        "):\n",
        "    \"\"\"\n",
        "    Разбиваем примеры на train / dev / test по script_id,\n",
        "    чтобы сцены одного сценария не попадали в разные сплиты.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "\n",
        "    by_script = defaultdict(list)\n",
        "    for ex in examples:\n",
        "        sid = ex[\"script_id\"]\n",
        "        by_script[sid].append(ex)\n",
        "\n",
        "    scripts = list(by_script.keys())\n",
        "    random.shuffle(scripts)\n",
        "\n",
        "    n_scripts = len(scripts)\n",
        "    n_train = int(n_scripts * train_ratio)\n",
        "    n_dev = int(n_scripts * dev_ratio)\n",
        "    n_test = n_scripts - n_train - n_dev\n",
        "\n",
        "    train_scripts = set(scripts[:n_train])\n",
        "    dev_scripts = set(scripts[n_train:n_train + n_dev])\n",
        "    test_scripts = set(scripts[n_train + n_dev:])\n",
        "\n",
        "    train, dev, test = [], [], []\n",
        "    for sid, scenes in by_script.items():\n",
        "        if sid in train_scripts:\n",
        "            train.extend(scenes)\n",
        "        elif sid in dev_scripts:\n",
        "            dev.extend(scenes)\n",
        "        else:\n",
        "            test.extend(scenes)\n",
        "\n",
        "    print(f\"Сценариев: всего={n_scripts}, train={len(train_scripts)}, dev={len(dev_scripts)}, test={len(test_scripts)}\")\n",
        "    print(f\"Примеров: train={len(train)}, dev={len(dev)}, test={len(test)}\")\n",
        "\n",
        "    return train, dev, test\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# MAIN\n",
        "# ---------------------------\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Выделение золотого стандарта из табличного датасета сценариев.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--input\",\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Путь к входному CSV/Excel с таблицей сцен.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\",\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Папка для сохранения JSONL (train/dev/test).\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--min_text_len\",\n",
        "        type=int,\n",
        "        default=50,\n",
        "        help=\"Минимальная длина текста сцены для попадания в золотой стандарт.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_examples\",\n",
        "        type=int,\n",
        "        default=0,\n",
        "        help=\"Максимальное количество примеров (0 = использовать все подходящие).\",\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    input_path = Path(args.input)\n",
        "    output_dir = Path(args.output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f\"Загружаем таблицу из: {input_path}\")\n",
        "    df = load_table(input_path)\n",
        "\n",
        "    print(\"Проверяем наличие обязательных колонок...\")\n",
        "    validate_columns(df)\n",
        "\n",
        "    print(\"Фильтруем сцены для золотого стандарта...\")\n",
        "    df_good = filter_good_scenes(df, min_text_len=args.min_text_len)\n",
        "    print(f\"Подходящих сцен: {len(df_good)}\")\n",
        "\n",
        "    print(\"Преобразуем строки в обучающие примеры...\")\n",
        "    examples = [row_to_example(row) for _, row in df_good.iterrows()]\n",
        "\n",
        "    if args.max_examples > 0 and len(examples) > args.max_examples:\n",
        "        print(f\"Ограничиваем число примеров до {args.max_examples}\")\n",
        "        examples = random.sample(examples, args.max_examples)\n",
        "\n",
        "    print(\"Разбиваем на train/dev/test по script_id...\")\n",
        "    train, dev, test = split_train_dev_test_by_script(examples)\n",
        "\n",
        "    print(\"Сохраняем JSONL-файлы...\")\n",
        "    save_jsonl(train, output_dir / \"gold_train.jsonl\")\n",
        "    save_jsonl(dev, output_dir / \"gold_dev.jsonl\")\n",
        "    save_jsonl(test, output_dir / \"gold_test.jsonl\")\n",
        "\n",
        "    print(\"Готово. Файлы сохранены:\")\n",
        "    print(f\"- {output_dir / 'gold_train.jsonl'}\")\n",
        "    print(f\"- {output_dir / 'gold_dev.jsonl'}\")\n",
        "    print(f\"- {output_dir / 'gold_test.jsonl'}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "0kPaYn6VBdfP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}